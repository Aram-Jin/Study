{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 100\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST 데이터셋\n",
    "trainset = datasets.FashionMNIST(\n",
    "    './.data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 (Generator)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([z, c], 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자 (Discriminator)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(794, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스를 만들고 모델의 가중치를 지정한 장치로 보내기\n",
    "D = Discriminator().to(DEVICE)\n",
    "G = Generator().to(DEVICE)\n",
    "\n",
    "# 이진 교차 엔트로피 함수와\n",
    "# 생성자와 판별자를 최적화할 Adam 모듈\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr =0.0002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr =0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이폭 [0/300] d_loss:0.1051 g_loss: 9.0508 D(x):0.97 D(G(z)):0.04\n",
      "이폭 [1/300] d_loss:0.4556 g_loss: 4.8771 D(x):0.86 D(G(z)):0.13\n",
      "이폭 [2/300] d_loss:0.4998 g_loss: 4.8106 D(x):0.86 D(G(z)):0.13\n",
      "이폭 [3/300] d_loss:0.3750 g_loss: 5.5137 D(x):0.87 D(G(z)):0.06\n",
      "이폭 [4/300] d_loss:0.4494 g_loss: 2.9839 D(x):0.87 D(G(z)):0.15\n",
      "이폭 [5/300] d_loss:0.5546 g_loss: 3.4189 D(x):0.83 D(G(z)):0.16\n",
      "이폭 [6/300] d_loss:0.4349 g_loss: 3.1455 D(x):0.86 D(G(z)):0.15\n",
      "이폭 [7/300] d_loss:0.6850 g_loss: 2.1963 D(x):0.88 D(G(z)):0.32\n",
      "이폭 [8/300] d_loss:0.5638 g_loss: 2.3106 D(x):0.79 D(G(z)):0.16\n",
      "이폭 [9/300] d_loss:1.0545 g_loss: 1.7984 D(x):0.72 D(G(z)):0.34\n",
      "이폭 [10/300] d_loss:0.7039 g_loss: 2.1651 D(x):0.74 D(G(z)):0.19\n",
      "이폭 [11/300] d_loss:0.7874 g_loss: 1.5662 D(x):0.76 D(G(z)):0.28\n",
      "이폭 [12/300] d_loss:0.9278 g_loss: 1.6638 D(x):0.65 D(G(z)):0.27\n",
      "이폭 [13/300] d_loss:0.7562 g_loss: 1.8321 D(x):0.76 D(G(z)):0.27\n",
      "이폭 [14/300] d_loss:1.0480 g_loss: 1.5936 D(x):0.67 D(G(z)):0.27\n",
      "이폭 [15/300] d_loss:0.9349 g_loss: 1.4522 D(x):0.75 D(G(z)):0.34\n",
      "이폭 [16/300] d_loss:0.9742 g_loss: 1.5591 D(x):0.69 D(G(z)):0.32\n",
      "이폭 [17/300] d_loss:0.7727 g_loss: 1.4488 D(x):0.75 D(G(z)):0.29\n",
      "이폭 [18/300] d_loss:1.2051 g_loss: 1.2141 D(x):0.60 D(G(z)):0.36\n",
      "이폭 [19/300] d_loss:0.9736 g_loss: 1.1591 D(x):0.72 D(G(z)):0.39\n",
      "이폭 [20/300] d_loss:1.0447 g_loss: 1.4652 D(x):0.63 D(G(z)):0.30\n",
      "이폭 [21/300] d_loss:1.0723 g_loss: 1.4785 D(x):0.60 D(G(z)):0.27\n",
      "이폭 [22/300] d_loss:0.9253 g_loss: 1.3343 D(x):0.69 D(G(z)):0.33\n",
      "이폭 [23/300] d_loss:1.1500 g_loss: 1.0818 D(x):0.69 D(G(z)):0.44\n",
      "이폭 [24/300] d_loss:1.1445 g_loss: 1.1635 D(x):0.58 D(G(z)):0.33\n",
      "이폭 [25/300] d_loss:1.1985 g_loss: 1.2555 D(x):0.55 D(G(z)):0.32\n",
      "이폭 [26/300] d_loss:0.8280 g_loss: 1.4404 D(x):0.74 D(G(z)):0.31\n",
      "이폭 [27/300] d_loss:1.0404 g_loss: 1.4795 D(x):0.66 D(G(z)):0.34\n",
      "이폭 [28/300] d_loss:1.0743 g_loss: 1.2389 D(x):0.65 D(G(z)):0.36\n",
      "이폭 [29/300] d_loss:0.8859 g_loss: 1.2920 D(x):0.72 D(G(z)):0.34\n",
      "이폭 [30/300] d_loss:1.1518 g_loss: 1.3991 D(x):0.60 D(G(z)):0.34\n",
      "이폭 [31/300] d_loss:1.3622 g_loss: 1.2237 D(x):0.51 D(G(z)):0.34\n",
      "이폭 [32/300] d_loss:1.1770 g_loss: 1.2646 D(x):0.65 D(G(z)):0.42\n",
      "이폭 [33/300] d_loss:1.1172 g_loss: 1.1285 D(x):0.64 D(G(z)):0.39\n",
      "이폭 [34/300] d_loss:0.8463 g_loss: 1.3027 D(x):0.74 D(G(z)):0.35\n",
      "이폭 [35/300] d_loss:1.1201 g_loss: 1.0366 D(x):0.63 D(G(z)):0.37\n",
      "이폭 [36/300] d_loss:1.0635 g_loss: 1.4242 D(x):0.61 D(G(z)):0.30\n",
      "이폭 [37/300] d_loss:1.1899 g_loss: 1.0571 D(x):0.63 D(G(z)):0.44\n",
      "이폭 [38/300] d_loss:1.1710 g_loss: 1.1158 D(x):0.66 D(G(z)):0.42\n",
      "이폭 [39/300] d_loss:1.1111 g_loss: 1.2070 D(x):0.60 D(G(z)):0.34\n",
      "이폭 [40/300] d_loss:0.8428 g_loss: 1.2787 D(x):0.74 D(G(z)):0.35\n",
      "이폭 [41/300] d_loss:1.1379 g_loss: 1.0677 D(x):0.62 D(G(z)):0.39\n",
      "이폭 [42/300] d_loss:1.0421 g_loss: 1.1543 D(x):0.67 D(G(z)):0.37\n",
      "이폭 [43/300] d_loss:1.1169 g_loss: 1.1615 D(x):0.65 D(G(z)):0.37\n",
      "이폭 [44/300] d_loss:1.2022 g_loss: 1.1449 D(x):0.59 D(G(z)):0.38\n",
      "이폭 [45/300] d_loss:1.1252 g_loss: 1.0986 D(x):0.62 D(G(z)):0.40\n",
      "이폭 [46/300] d_loss:1.1978 g_loss: 1.2591 D(x):0.64 D(G(z)):0.39\n",
      "이폭 [47/300] d_loss:1.0854 g_loss: 1.0345 D(x):0.64 D(G(z)):0.41\n",
      "이폭 [48/300] d_loss:0.9542 g_loss: 1.1056 D(x):0.69 D(G(z)):0.36\n",
      "이폭 [49/300] d_loss:1.1088 g_loss: 1.2019 D(x):0.62 D(G(z)):0.36\n",
      "이폭 [50/300] d_loss:1.1059 g_loss: 1.2320 D(x):0.61 D(G(z)):0.35\n",
      "이폭 [51/300] d_loss:1.2189 g_loss: 1.3144 D(x):0.59 D(G(z)):0.38\n",
      "이폭 [52/300] d_loss:1.0007 g_loss: 1.1495 D(x):0.67 D(G(z)):0.34\n",
      "이폭 [53/300] d_loss:1.2175 g_loss: 1.0692 D(x):0.58 D(G(z)):0.39\n",
      "이폭 [54/300] d_loss:1.0917 g_loss: 1.2190 D(x):0.64 D(G(z)):0.35\n",
      "이폭 [55/300] d_loss:1.3712 g_loss: 0.9049 D(x):0.55 D(G(z)):0.45\n",
      "이폭 [56/300] d_loss:1.1449 g_loss: 1.1868 D(x):0.60 D(G(z)):0.36\n",
      "이폭 [57/300] d_loss:1.2025 g_loss: 1.0193 D(x):0.59 D(G(z)):0.41\n",
      "이폭 [58/300] d_loss:1.2583 g_loss: 1.0450 D(x):0.59 D(G(z)):0.42\n",
      "이폭 [59/300] d_loss:0.9609 g_loss: 1.1388 D(x):0.69 D(G(z)):0.37\n",
      "이폭 [60/300] d_loss:1.1498 g_loss: 1.0822 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [61/300] d_loss:1.0357 g_loss: 1.1834 D(x):0.65 D(G(z)):0.35\n",
      "이폭 [62/300] d_loss:1.2670 g_loss: 1.2460 D(x):0.55 D(G(z)):0.36\n",
      "이폭 [63/300] d_loss:1.0545 g_loss: 1.1382 D(x):0.69 D(G(z)):0.41\n",
      "이폭 [64/300] d_loss:1.1546 g_loss: 1.1592 D(x):0.60 D(G(z)):0.37\n",
      "이폭 [65/300] d_loss:0.9104 g_loss: 1.2622 D(x):0.70 D(G(z)):0.36\n",
      "이폭 [66/300] d_loss:1.3143 g_loss: 1.2310 D(x):0.51 D(G(z)):0.36\n",
      "이폭 [67/300] d_loss:1.1609 g_loss: 1.0250 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [68/300] d_loss:1.3431 g_loss: 1.0397 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [69/300] d_loss:1.0564 g_loss: 1.2124 D(x):0.64 D(G(z)):0.35\n",
      "이폭 [70/300] d_loss:0.9132 g_loss: 1.3671 D(x):0.67 D(G(z)):0.32\n",
      "이폭 [71/300] d_loss:1.0596 g_loss: 1.0983 D(x):0.65 D(G(z)):0.37\n",
      "이폭 [72/300] d_loss:1.5009 g_loss: 1.4144 D(x):0.50 D(G(z)):0.36\n",
      "이폭 [73/300] d_loss:1.0751 g_loss: 0.9564 D(x):0.67 D(G(z)):0.43\n",
      "이폭 [74/300] d_loss:1.2437 g_loss: 1.1531 D(x):0.58 D(G(z)):0.40\n",
      "이폭 [75/300] d_loss:1.3012 g_loss: 0.8074 D(x):0.56 D(G(z)):0.47\n",
      "이폭 [76/300] d_loss:1.1327 g_loss: 1.1191 D(x):0.62 D(G(z)):0.39\n",
      "이폭 [77/300] d_loss:1.2795 g_loss: 0.9851 D(x):0.58 D(G(z)):0.44\n",
      "이폭 [78/300] d_loss:1.2594 g_loss: 0.7964 D(x):0.59 D(G(z)):0.46\n",
      "이폭 [79/300] d_loss:1.1768 g_loss: 1.1105 D(x):0.58 D(G(z)):0.38\n",
      "이폭 [80/300] d_loss:1.3640 g_loss: 1.0334 D(x):0.57 D(G(z)):0.43\n",
      "이폭 [81/300] d_loss:1.1402 g_loss: 0.9399 D(x):0.60 D(G(z)):0.41\n",
      "이폭 [82/300] d_loss:1.3510 g_loss: 0.9025 D(x):0.55 D(G(z)):0.45\n",
      "이폭 [83/300] d_loss:1.3701 g_loss: 0.9153 D(x):0.55 D(G(z)):0.44\n",
      "이폭 [84/300] d_loss:1.2654 g_loss: 1.4133 D(x):0.53 D(G(z)):0.30\n",
      "이폭 [85/300] d_loss:1.1778 g_loss: 0.9824 D(x):0.58 D(G(z)):0.42\n",
      "이폭 [86/300] d_loss:1.0750 g_loss: 0.9848 D(x):0.63 D(G(z)):0.40\n",
      "이폭 [87/300] d_loss:1.0358 g_loss: 1.2144 D(x):0.67 D(G(z)):0.36\n",
      "이폭 [88/300] d_loss:1.1223 g_loss: 1.2830 D(x):0.58 D(G(z)):0.34\n",
      "이폭 [89/300] d_loss:1.1357 g_loss: 1.1650 D(x):0.60 D(G(z)):0.36\n",
      "이폭 [90/300] d_loss:1.1553 g_loss: 1.0305 D(x):0.59 D(G(z)):0.41\n",
      "이폭 [91/300] d_loss:1.1442 g_loss: 1.0358 D(x):0.61 D(G(z)):0.41\n",
      "이폭 [92/300] d_loss:1.1175 g_loss: 1.0285 D(x):0.60 D(G(z)):0.40\n",
      "이폭 [93/300] d_loss:1.2617 g_loss: 0.9676 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [94/300] d_loss:1.1411 g_loss: 0.9308 D(x):0.63 D(G(z)):0.43\n",
      "이폭 [95/300] d_loss:1.1569 g_loss: 1.1378 D(x):0.57 D(G(z)):0.36\n",
      "이폭 [96/300] d_loss:1.2624 g_loss: 1.0864 D(x):0.58 D(G(z)):0.38\n",
      "이폭 [97/300] d_loss:1.1696 g_loss: 1.0938 D(x):0.57 D(G(z)):0.38\n",
      "이폭 [98/300] d_loss:1.2339 g_loss: 0.9029 D(x):0.58 D(G(z)):0.46\n",
      "이폭 [99/300] d_loss:1.2720 g_loss: 0.8946 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [100/300] d_loss:0.9415 g_loss: 1.4448 D(x):0.68 D(G(z)):0.29\n",
      "이폭 [101/300] d_loss:1.2385 g_loss: 1.0622 D(x):0.60 D(G(z)):0.41\n",
      "이폭 [102/300] d_loss:1.1328 g_loss: 1.2824 D(x):0.58 D(G(z)):0.34\n",
      "이폭 [103/300] d_loss:1.2211 g_loss: 0.8084 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [104/300] d_loss:1.2605 g_loss: 0.9615 D(x):0.55 D(G(z)):0.43\n",
      "이폭 [105/300] d_loss:1.2948 g_loss: 0.8625 D(x):0.53 D(G(z)):0.43\n",
      "이폭 [106/300] d_loss:1.3237 g_loss: 1.1870 D(x):0.53 D(G(z)):0.36\n",
      "이폭 [107/300] d_loss:1.1775 g_loss: 1.2113 D(x):0.62 D(G(z)):0.39\n",
      "이폭 [108/300] d_loss:1.0716 g_loss: 1.4078 D(x):0.64 D(G(z)):0.32\n",
      "이폭 [109/300] d_loss:1.2213 g_loss: 1.0289 D(x):0.62 D(G(z)):0.42\n",
      "이폭 [110/300] d_loss:1.2205 g_loss: 0.9941 D(x):0.57 D(G(z)):0.41\n",
      "이폭 [111/300] d_loss:1.2787 g_loss: 0.9530 D(x):0.61 D(G(z)):0.45\n",
      "이폭 [112/300] d_loss:1.1769 g_loss: 1.0670 D(x):0.63 D(G(z)):0.40\n",
      "이폭 [113/300] d_loss:1.1833 g_loss: 1.2020 D(x):0.63 D(G(z)):0.40\n",
      "이폭 [114/300] d_loss:1.3248 g_loss: 0.8482 D(x):0.56 D(G(z)):0.45\n",
      "이폭 [115/300] d_loss:1.4072 g_loss: 0.7973 D(x):0.54 D(G(z)):0.49\n",
      "이폭 [116/300] d_loss:1.1403 g_loss: 1.0458 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [117/300] d_loss:1.1158 g_loss: 1.0894 D(x):0.59 D(G(z)):0.38\n",
      "이폭 [118/300] d_loss:1.2311 g_loss: 1.1565 D(x):0.65 D(G(z)):0.43\n",
      "이폭 [119/300] d_loss:1.1234 g_loss: 0.9203 D(x):0.66 D(G(z)):0.43\n",
      "이폭 [120/300] d_loss:1.1319 g_loss: 0.9736 D(x):0.61 D(G(z)):0.42\n",
      "이폭 [121/300] d_loss:1.1580 g_loss: 1.1745 D(x):0.63 D(G(z)):0.38\n",
      "이폭 [122/300] d_loss:1.1954 g_loss: 1.0138 D(x):0.63 D(G(z)):0.43\n",
      "이폭 [123/300] d_loss:1.2238 g_loss: 0.9104 D(x):0.60 D(G(z)):0.44\n",
      "이폭 [124/300] d_loss:1.2508 g_loss: 1.2048 D(x):0.57 D(G(z)):0.37\n",
      "이폭 [125/300] d_loss:1.3224 g_loss: 0.9996 D(x):0.53 D(G(z)):0.43\n",
      "이폭 [126/300] d_loss:1.2796 g_loss: 1.0699 D(x):0.54 D(G(z)):0.41\n",
      "이폭 [127/300] d_loss:1.3709 g_loss: 1.0675 D(x):0.53 D(G(z)):0.44\n",
      "이폭 [128/300] d_loss:1.1489 g_loss: 0.9158 D(x):0.62 D(G(z)):0.44\n",
      "이폭 [129/300] d_loss:1.1069 g_loss: 1.1476 D(x):0.59 D(G(z)):0.36\n",
      "이폭 [130/300] d_loss:1.2773 g_loss: 1.2202 D(x):0.56 D(G(z)):0.36\n",
      "이폭 [131/300] d_loss:1.3818 g_loss: 1.0210 D(x):0.56 D(G(z)):0.44\n",
      "이폭 [132/300] d_loss:1.1959 g_loss: 0.9576 D(x):0.59 D(G(z)):0.43\n",
      "이폭 [133/300] d_loss:1.3143 g_loss: 1.0838 D(x):0.56 D(G(z)):0.39\n",
      "이폭 [134/300] d_loss:1.2768 g_loss: 0.9208 D(x):0.57 D(G(z)):0.43\n",
      "이폭 [135/300] d_loss:1.1528 g_loss: 0.9768 D(x):0.61 D(G(z)):0.41\n",
      "이폭 [136/300] d_loss:1.2281 g_loss: 0.9703 D(x):0.61 D(G(z)):0.44\n",
      "이폭 [137/300] d_loss:1.2185 g_loss: 1.1573 D(x):0.58 D(G(z)):0.38\n",
      "이폭 [138/300] d_loss:1.2183 g_loss: 0.8651 D(x):0.62 D(G(z)):0.45\n",
      "이폭 [139/300] d_loss:1.1258 g_loss: 1.0121 D(x):0.63 D(G(z)):0.42\n",
      "이폭 [140/300] d_loss:1.2138 g_loss: 1.1435 D(x):0.57 D(G(z)):0.40\n",
      "이폭 [141/300] d_loss:1.1939 g_loss: 0.9590 D(x):0.57 D(G(z)):0.40\n",
      "이폭 [142/300] d_loss:1.2015 g_loss: 0.9295 D(x):0.61 D(G(z)):0.44\n",
      "이폭 [143/300] d_loss:1.1609 g_loss: 1.0267 D(x):0.62 D(G(z)):0.43\n",
      "이폭 [144/300] d_loss:1.2899 g_loss: 0.8981 D(x):0.56 D(G(z)):0.45\n",
      "이폭 [145/300] d_loss:1.1769 g_loss: 1.0317 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [146/300] d_loss:1.1810 g_loss: 1.2185 D(x):0.65 D(G(z)):0.42\n",
      "이폭 [147/300] d_loss:1.1217 g_loss: 1.1367 D(x):0.62 D(G(z)):0.38\n",
      "이폭 [148/300] d_loss:1.2282 g_loss: 0.9602 D(x):0.53 D(G(z)):0.38\n",
      "이폭 [149/300] d_loss:1.2917 g_loss: 0.9636 D(x):0.58 D(G(z)):0.44\n",
      "이폭 [150/300] d_loss:1.2464 g_loss: 1.0241 D(x):0.55 D(G(z)):0.40\n",
      "이폭 [151/300] d_loss:1.1572 g_loss: 0.9807 D(x):0.59 D(G(z)):0.43\n",
      "이폭 [152/300] d_loss:1.0965 g_loss: 1.0735 D(x):0.66 D(G(z)):0.43\n",
      "이폭 [153/300] d_loss:1.1284 g_loss: 1.1401 D(x):0.60 D(G(z)):0.39\n",
      "이폭 [154/300] d_loss:1.1095 g_loss: 1.0021 D(x):0.62 D(G(z)):0.40\n",
      "이폭 [155/300] d_loss:1.0777 g_loss: 1.0842 D(x):0.59 D(G(z)):0.35\n",
      "이폭 [156/300] d_loss:1.2250 g_loss: 0.9176 D(x):0.59 D(G(z)):0.44\n",
      "이폭 [157/300] d_loss:1.0766 g_loss: 1.1121 D(x):0.60 D(G(z)):0.37\n",
      "이폭 [158/300] d_loss:1.2590 g_loss: 0.8845 D(x):0.54 D(G(z)):0.42\n",
      "이폭 [159/300] d_loss:1.2168 g_loss: 1.2149 D(x):0.60 D(G(z)):0.39\n",
      "이폭 [160/300] d_loss:1.2578 g_loss: 0.9786 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [161/300] d_loss:1.2117 g_loss: 0.9816 D(x):0.53 D(G(z)):0.38\n",
      "이폭 [162/300] d_loss:1.1086 g_loss: 1.2426 D(x):0.60 D(G(z)):0.38\n",
      "이폭 [163/300] d_loss:1.1929 g_loss: 1.0685 D(x):0.58 D(G(z)):0.40\n",
      "이폭 [164/300] d_loss:1.2149 g_loss: 1.0001 D(x):0.57 D(G(z)):0.40\n",
      "이폭 [165/300] d_loss:1.2404 g_loss: 1.0073 D(x):0.57 D(G(z)):0.43\n",
      "이폭 [166/300] d_loss:1.1588 g_loss: 0.8489 D(x):0.63 D(G(z)):0.44\n",
      "이폭 [167/300] d_loss:1.3402 g_loss: 0.6650 D(x):0.59 D(G(z)):0.52\n",
      "이폭 [168/300] d_loss:1.2204 g_loss: 0.9951 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [169/300] d_loss:1.2383 g_loss: 0.9152 D(x):0.58 D(G(z)):0.45\n",
      "이폭 [170/300] d_loss:1.1972 g_loss: 0.8859 D(x):0.61 D(G(z)):0.44\n",
      "이폭 [171/300] d_loss:1.3230 g_loss: 0.9373 D(x):0.54 D(G(z)):0.43\n",
      "이폭 [172/300] d_loss:1.3429 g_loss: 0.8750 D(x):0.55 D(G(z)):0.46\n",
      "이폭 [173/300] d_loss:1.2382 g_loss: 1.1573 D(x):0.61 D(G(z)):0.39\n",
      "이폭 [174/300] d_loss:1.1600 g_loss: 1.0181 D(x):0.58 D(G(z)):0.39\n",
      "이폭 [175/300] d_loss:1.2954 g_loss: 0.9390 D(x):0.54 D(G(z)):0.43\n",
      "이폭 [176/300] d_loss:1.3225 g_loss: 0.7674 D(x):0.58 D(G(z)):0.49\n",
      "이폭 [177/300] d_loss:1.1622 g_loss: 0.9395 D(x):0.63 D(G(z)):0.43\n",
      "이폭 [178/300] d_loss:1.1444 g_loss: 0.9442 D(x):0.59 D(G(z)):0.42\n",
      "이폭 [179/300] d_loss:1.2532 g_loss: 1.0463 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [180/300] d_loss:1.4036 g_loss: 0.7878 D(x):0.51 D(G(z)):0.48\n",
      "이폭 [181/300] d_loss:1.2200 g_loss: 1.0083 D(x):0.61 D(G(z)):0.44\n",
      "이폭 [182/300] d_loss:1.2316 g_loss: 1.0508 D(x):0.62 D(G(z)):0.42\n",
      "이폭 [183/300] d_loss:1.2515 g_loss: 0.9258 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [184/300] d_loss:1.2554 g_loss: 0.9154 D(x):0.55 D(G(z)):0.41\n",
      "이폭 [185/300] d_loss:1.1712 g_loss: 1.0707 D(x):0.62 D(G(z)):0.42\n",
      "이폭 [186/300] d_loss:1.1206 g_loss: 1.0092 D(x):0.63 D(G(z)):0.41\n",
      "이폭 [187/300] d_loss:1.1654 g_loss: 0.9774 D(x):0.58 D(G(z)):0.40\n",
      "이폭 [188/300] d_loss:1.0748 g_loss: 1.1033 D(x):0.66 D(G(z)):0.41\n",
      "이폭 [189/300] d_loss:1.2395 g_loss: 0.9195 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [190/300] d_loss:1.2033 g_loss: 1.0158 D(x):0.58 D(G(z)):0.38\n",
      "이폭 [191/300] d_loss:1.1107 g_loss: 0.9578 D(x):0.59 D(G(z)):0.39\n",
      "이폭 [192/300] d_loss:1.2509 g_loss: 1.0245 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [193/300] d_loss:1.2293 g_loss: 0.9363 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [194/300] d_loss:1.2310 g_loss: 0.7769 D(x):0.58 D(G(z)):0.47\n",
      "이폭 [195/300] d_loss:1.2621 g_loss: 0.9010 D(x):0.58 D(G(z)):0.41\n",
      "이폭 [196/300] d_loss:1.2830 g_loss: 0.8542 D(x):0.60 D(G(z)):0.48\n",
      "이폭 [197/300] d_loss:1.1322 g_loss: 0.9465 D(x):0.62 D(G(z)):0.42\n",
      "이폭 [198/300] d_loss:1.0393 g_loss: 1.2262 D(x):0.67 D(G(z)):0.35\n",
      "이폭 [199/300] d_loss:1.5950 g_loss: 0.8983 D(x):0.52 D(G(z)):0.49\n",
      "이폭 [200/300] d_loss:1.2983 g_loss: 0.9583 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [201/300] d_loss:1.2835 g_loss: 0.7763 D(x):0.59 D(G(z)):0.48\n",
      "이폭 [202/300] d_loss:1.2277 g_loss: 1.1182 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [203/300] d_loss:1.1876 g_loss: 1.1358 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [204/300] d_loss:1.2217 g_loss: 0.8166 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [205/300] d_loss:1.3792 g_loss: 0.7881 D(x):0.56 D(G(z)):0.49\n",
      "이폭 [206/300] d_loss:1.1658 g_loss: 1.1195 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [207/300] d_loss:1.1273 g_loss: 0.9820 D(x):0.60 D(G(z)):0.41\n",
      "이폭 [208/300] d_loss:1.2634 g_loss: 1.0281 D(x):0.55 D(G(z)):0.41\n",
      "이폭 [209/300] d_loss:1.1269 g_loss: 1.0087 D(x):0.69 D(G(z)):0.45\n",
      "이폭 [210/300] d_loss:1.4239 g_loss: 1.0163 D(x):0.52 D(G(z)):0.41\n",
      "이폭 [211/300] d_loss:1.3411 g_loss: 1.0056 D(x):0.52 D(G(z)):0.42\n",
      "이폭 [212/300] d_loss:1.2506 g_loss: 0.8137 D(x):0.58 D(G(z)):0.46\n",
      "이폭 [213/300] d_loss:1.2468 g_loss: 0.9544 D(x):0.58 D(G(z)):0.45\n",
      "이폭 [214/300] d_loss:1.2247 g_loss: 0.9391 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [215/300] d_loss:1.3626 g_loss: 0.8596 D(x):0.51 D(G(z)):0.42\n",
      "이폭 [216/300] d_loss:1.3599 g_loss: 0.8204 D(x):0.55 D(G(z)):0.48\n",
      "이폭 [217/300] d_loss:1.2383 g_loss: 0.9513 D(x):0.55 D(G(z)):0.41\n",
      "이폭 [218/300] d_loss:1.2680 g_loss: 0.9039 D(x):0.58 D(G(z)):0.44\n",
      "이폭 [219/300] d_loss:1.1802 g_loss: 0.8141 D(x):0.62 D(G(z)):0.44\n",
      "이폭 [220/300] d_loss:1.3475 g_loss: 1.1391 D(x):0.56 D(G(z)):0.44\n",
      "이폭 [221/300] d_loss:1.3927 g_loss: 0.8773 D(x):0.55 D(G(z)):0.45\n",
      "이폭 [222/300] d_loss:1.3189 g_loss: 0.9766 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [223/300] d_loss:1.2110 g_loss: 1.0010 D(x):0.54 D(G(z)):0.38\n",
      "이폭 [224/300] d_loss:1.2896 g_loss: 0.8879 D(x):0.54 D(G(z)):0.43\n",
      "이폭 [225/300] d_loss:1.2975 g_loss: 1.0245 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [226/300] d_loss:1.0806 g_loss: 1.1112 D(x):0.61 D(G(z)):0.37\n",
      "이폭 [227/300] d_loss:1.3531 g_loss: 0.9958 D(x):0.53 D(G(z)):0.42\n",
      "이폭 [228/300] d_loss:1.1961 g_loss: 0.8801 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [229/300] d_loss:1.2801 g_loss: 1.2595 D(x):0.54 D(G(z)):0.38\n",
      "이폭 [230/300] d_loss:1.3337 g_loss: 0.8257 D(x):0.53 D(G(z)):0.47\n",
      "이폭 [231/300] d_loss:1.2386 g_loss: 0.9415 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [232/300] d_loss:1.0601 g_loss: 1.0734 D(x):0.69 D(G(z)):0.38\n",
      "이폭 [233/300] d_loss:1.2831 g_loss: 0.7807 D(x):0.56 D(G(z)):0.48\n",
      "이폭 [234/300] d_loss:1.3003 g_loss: 0.9745 D(x):0.53 D(G(z)):0.42\n",
      "이폭 [235/300] d_loss:1.2884 g_loss: 0.9111 D(x):0.60 D(G(z)):0.47\n",
      "이폭 [236/300] d_loss:1.2657 g_loss: 0.9155 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [237/300] d_loss:1.1213 g_loss: 0.9366 D(x):0.63 D(G(z)):0.44\n",
      "이폭 [238/300] d_loss:1.2850 g_loss: 0.9679 D(x):0.59 D(G(z)):0.44\n",
      "이폭 [239/300] d_loss:1.3840 g_loss: 0.6847 D(x):0.57 D(G(z)):0.51\n",
      "이폭 [240/300] d_loss:1.2240 g_loss: 0.9444 D(x):0.56 D(G(z)):0.41\n",
      "이폭 [241/300] d_loss:1.2858 g_loss: 1.2623 D(x):0.58 D(G(z)):0.38\n",
      "이폭 [242/300] d_loss:1.3113 g_loss: 0.9468 D(x):0.58 D(G(z)):0.45\n",
      "이폭 [243/300] d_loss:1.3341 g_loss: 0.9130 D(x):0.53 D(G(z)):0.44\n",
      "이폭 [244/300] d_loss:1.3993 g_loss: 0.8407 D(x):0.54 D(G(z)):0.47\n",
      "이폭 [245/300] d_loss:1.1977 g_loss: 0.9045 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [246/300] d_loss:1.1240 g_loss: 0.8474 D(x):0.62 D(G(z)):0.45\n",
      "이폭 [247/300] d_loss:1.1167 g_loss: 0.9516 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [248/300] d_loss:1.2458 g_loss: 1.1208 D(x):0.58 D(G(z)):0.40\n",
      "이폭 [249/300] d_loss:1.1472 g_loss: 0.9660 D(x):0.58 D(G(z)):0.39\n",
      "이폭 [250/300] d_loss:1.3223 g_loss: 0.8889 D(x):0.53 D(G(z)):0.43\n",
      "이폭 [251/300] d_loss:1.2849 g_loss: 0.9800 D(x):0.55 D(G(z)):0.43\n",
      "이폭 [252/300] d_loss:1.2867 g_loss: 0.9344 D(x):0.54 D(G(z)):0.43\n",
      "이폭 [253/300] d_loss:1.1035 g_loss: 1.0075 D(x):0.65 D(G(z)):0.41\n",
      "이폭 [254/300] d_loss:1.4143 g_loss: 0.8709 D(x):0.52 D(G(z)):0.47\n",
      "이폭 [255/300] d_loss:1.2985 g_loss: 0.9099 D(x):0.60 D(G(z)):0.46\n",
      "이폭 [256/300] d_loss:1.1482 g_loss: 1.3225 D(x):0.60 D(G(z)):0.38\n",
      "이폭 [257/300] d_loss:1.3242 g_loss: 0.9340 D(x):0.54 D(G(z)):0.44\n",
      "이폭 [258/300] d_loss:1.1571 g_loss: 1.3645 D(x):0.57 D(G(z)):0.33\n",
      "이폭 [259/300] d_loss:1.2478 g_loss: 0.8472 D(x):0.58 D(G(z)):0.46\n",
      "이폭 [260/300] d_loss:1.1921 g_loss: 1.0813 D(x):0.57 D(G(z)):0.38\n",
      "이폭 [261/300] d_loss:1.2425 g_loss: 1.0646 D(x):0.53 D(G(z)):0.38\n",
      "이폭 [262/300] d_loss:1.4128 g_loss: 0.8036 D(x):0.53 D(G(z)):0.49\n",
      "이폭 [263/300] d_loss:1.2594 g_loss: 1.0701 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [264/300] d_loss:1.2449 g_loss: 0.8520 D(x):0.59 D(G(z)):0.45\n",
      "이폭 [265/300] d_loss:1.2551 g_loss: 0.9880 D(x):0.57 D(G(z)):0.40\n",
      "이폭 [266/300] d_loss:1.3385 g_loss: 1.0498 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [267/300] d_loss:1.2982 g_loss: 1.0819 D(x):0.60 D(G(z)):0.41\n",
      "이폭 [268/300] d_loss:1.2494 g_loss: 1.0940 D(x):0.58 D(G(z)):0.38\n",
      "이폭 [269/300] d_loss:1.2613 g_loss: 0.9489 D(x):0.56 D(G(z)):0.44\n",
      "이폭 [270/300] d_loss:1.3089 g_loss: 0.8759 D(x):0.55 D(G(z)):0.45\n",
      "이폭 [271/300] d_loss:1.3026 g_loss: 0.8631 D(x):0.53 D(G(z)):0.44\n",
      "이폭 [272/300] d_loss:1.1449 g_loss: 0.8875 D(x):0.60 D(G(z)):0.43\n",
      "이폭 [273/300] d_loss:1.3252 g_loss: 0.7727 D(x):0.58 D(G(z)):0.49\n",
      "이폭 [274/300] d_loss:1.2874 g_loss: 0.9728 D(x):0.58 D(G(z)):0.41\n",
      "이폭 [275/300] d_loss:1.2070 g_loss: 0.9666 D(x):0.59 D(G(z)):0.43\n",
      "이폭 [276/300] d_loss:1.1946 g_loss: 0.9300 D(x):0.61 D(G(z)):0.44\n",
      "이폭 [277/300] d_loss:1.1884 g_loss: 0.9757 D(x):0.60 D(G(z)):0.42\n",
      "이폭 [278/300] d_loss:1.2823 g_loss: 1.0859 D(x):0.55 D(G(z)):0.38\n",
      "이폭 [279/300] d_loss:1.3470 g_loss: 0.8228 D(x):0.52 D(G(z)):0.45\n",
      "이폭 [280/300] d_loss:1.2112 g_loss: 1.0817 D(x):0.59 D(G(z)):0.39\n",
      "이폭 [281/300] d_loss:1.2961 g_loss: 0.9089 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [282/300] d_loss:1.3918 g_loss: 0.8274 D(x):0.53 D(G(z)):0.47\n",
      "이폭 [283/300] d_loss:1.0673 g_loss: 1.1644 D(x):0.64 D(G(z)):0.36\n",
      "이폭 [284/300] d_loss:1.2504 g_loss: 0.9648 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [285/300] d_loss:1.2689 g_loss: 0.8889 D(x):0.56 D(G(z)):0.45\n",
      "이폭 [286/300] d_loss:1.3445 g_loss: 0.8723 D(x):0.51 D(G(z)):0.42\n",
      "이폭 [287/300] d_loss:1.4472 g_loss: 0.8918 D(x):0.56 D(G(z)):0.50\n",
      "이폭 [288/300] d_loss:1.2062 g_loss: 0.9767 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [289/300] d_loss:1.2317 g_loss: 0.8191 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [290/300] d_loss:1.1911 g_loss: 1.0496 D(x):0.57 D(G(z)):0.39\n",
      "이폭 [291/300] d_loss:1.1833 g_loss: 0.8551 D(x):0.60 D(G(z)):0.45\n",
      "이폭 [292/300] d_loss:1.3709 g_loss: 0.8191 D(x):0.53 D(G(z)):0.47\n",
      "이폭 [293/300] d_loss:1.1838 g_loss: 0.9439 D(x):0.58 D(G(z)):0.42\n",
      "이폭 [294/300] d_loss:1.4845 g_loss: 1.1263 D(x):0.50 D(G(z)):0.43\n",
      "이폭 [295/300] d_loss:1.2730 g_loss: 0.9135 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [296/300] d_loss:1.2956 g_loss: 1.0123 D(x):0.53 D(G(z)):0.41\n",
      "이폭 [297/300] d_loss:1.1945 g_loss: 0.9226 D(x):0.59 D(G(z)):0.43\n",
      "이폭 [298/300] d_loss:1.3081 g_loss: 0.7792 D(x):0.54 D(G(z)):0.47\n",
      "이폭 [299/300] d_loss:1.3055 g_loss: 0.9012 D(x):0.57 D(G(z)):0.45\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE)\n",
    "        \n",
    "        # '진짜'와 '가짜' 레이블 생성\n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "\n",
    "        # 판별자가 진짜 이미지를 진짜로 인식하는 오차 계산 (데이터셋 레이블 입력)\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = D(images, labels)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "    \n",
    "        # 무작위 텐서와 무작위 레이블을 생성자에 입력해 가짜 이미지 생성\n",
    "        z = torch.randn(BATCH_SIZE, 100).to(DEVICE)\n",
    "        g_label = torch.randint(0, 10, (BATCH_SIZE,)).to(DEVICE)\n",
    "        fake_images = G(z, g_label)\n",
    "        \n",
    "        # 판별자가 가짜 이미지를 가짜로 인식하는 오차 계산\n",
    "        outputs = D(fake_images, g_label)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # 진짜와 가짜 이미지를 갖고 낸 오차를 더해서 판별자의 오차 계산\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        # 역전파 알고리즘으로 판별자 모델의 학습을 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # 생성자가 판별자를 속였는지에 대한 오차 계산(무작위 레이블 입력)\n",
    "        fake_images = G(z, g_label)\n",
    "        outputs = D(fake_images, g_label)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "\n",
    "        # 역전파 알고리즘으로 생성자 모델의 학습을 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "    print('이폭 [{}/{}] d_loss:{:.4f} g_loss: {:.4f} D(x):{:.2f} D(G(z)):{:.2f}'\n",
    "          .format(epoch,\n",
    "                  EPOCHS,\n",
    "                  d_loss.item(),\n",
    "                  g_loss.item(),\n",
    "                  real_score.mean().item(),\n",
    "                  fake_score.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23960/3484144517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfake_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfake_images_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_images_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'labels'"
     ]
    }
   ],
   "source": [
    "z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "fake_images = G(z)\n",
    "for i in range(10):\n",
    "    fake_images_img = np.reshape(fake_images.data.cpu().numpy()[i],(28,28))\n",
    "    plt.imshow(fake_images_img, cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "594ce620ff6a5f20b43ad5e4bebf44938ee5c8eae13890c13b673e8e3f3596cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
