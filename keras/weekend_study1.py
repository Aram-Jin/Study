from numpy.core.fromnumeric import shape
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import numpy as np
from sklearn import datasets
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping

#1. 데이터
datasets = load_boston()
x = datasets.data
y = datasets.target

print(x)
print(y)
print(x.shape) # (506, 13)
print(y.shape) # (506, )

x_train, x_test, y_train, y_test = train_test_split(x, y,
                                                    train_size=0.7, shuffle=True, random_state=55)

print(x_train.shape)

#2.
model = Sequential
model.add(Dense(500, input_dim = 13))
model.add(Dense(400))
model.add(Dense(300))
model.add(Dense(200))
model.add(Dense(100))
model.add(Dense(50))
model.add(Dense(1))

#3. 
model.compile(loss='mse', optimizer='adam')
es = EarlyStopping(monitor='val_loss', patience='50',  )



'''
hist = [88.92745971679688, 100.0557861328125, 89.13023376464844, 129.5458526611328, 72.54454040527344, 75.412841796875, 93.310791015625, 69.37403869628906, 74.30789184570312, 69.27983093261719, 82.31840515136719, 72.51094818115234, 83.70752716064453, 63.300228118896484, 142.2508544921875, 55.46793746948242, 92.70178985595703, 93.5816879272461, 69.86042022705078, 55.73990249633789, 92.49964141845703, 81.20714569091797, 64.60222625732422, 55.87809753417969, 49.21889877319336, 62.30656051635742, 49.27598571777344, 62.677494049072266, 74.61087036132812, 67.97299194335938, 42.7689094543457, 46.27736282348633, 46.264122009277344, 50.24428939819336, 54.016353607177734, 66.74417877197266, 51.11172103881836, 68.18479919433594, 43.75231170654297, 56.6058349609375, 44.85729217529297, 47.67927932739258, 49.39921569824219, 57.31904602050781, 55.751705169677734, 46.15977478027344, 49.58647918701172, 39.07254409790039, 51.97351837158203, 45.84427261352539, 50.75863265991211, 57.3486328125, 40.6578254699707, 41.212154388427734, 38.99170684814453, 39.284793853759766, 42.79259490966797, 50.947608947753906, 54.10773468017578, 50.17550277709961, 49.02544403076172, 43.84046173095703, 56.30613327026367, 38.03791427612305, 37.687191009521484, 39.56721496582031, 38.93086624145508, 48.91346740722656, 38.81944274902344, 36.96547317504883, 50.81501388549805, 40.382503509521484, 52.97557830810547, 51.48081970214844, 57.190303802490234, 38.16039276123047, 43.90409469604492, 39.67534255981445, 40.15404510498047, 40.3061637878418, 46.70872497558594, 40.783294677734375, 40.237396240234375, 36.85731506347656, 36.742271423339844, 39.79767608642578, 37.898345947265625, 36.171539306640625, 43.680030822753906, 35.96021270751953, 37.58179473876953, 36.79806900024414, 50.84257888793945, 40.185455322265625, 52.66645050048828, 38.830322265625, 42.27733612060547, 40.938201904296875, 40.939208984375, 47.46600341796875, 35.50605773925781, 34.967838287353516, 35.9568977355957, 46.9338264465332, 47.22172164916992, 51.45296859741211, 34.81958770751953, 57.85084533691406, 40.3226318359375, 36.96831512451172, 34.55339431762695, 38.70804214477539, 44.205322265625, 41.13291549682617, 37.340660095214844, 36.42295455932617, 42.094058990478516, 41.470829010009766, 37.35600662231445, 35.92408752441406, 47.17573547363281, 35.842403411865234, 41.59393310546875, 35.64619064331055, 36.20427322387695, 40.89995574951172, 36.32892608642578, 64.40077209472656, 38.085872650146484, 37.563621520996094, 38.04740524291992, 37.21397399902344, 48.37899398803711, 41.36591720581055, 34.558109283447266, 42.794898986816406, 51.83805847167969, 46.491641998291016, 41.16407012939453, 37.21647644042969, 35.46665954589844, 34.02632141113281, 41.038814544677734, 35.62171173095703, 40.65577697753906, 36.78068161010742, 37.27362060546875, 37.28616714477539, 36.29750061035156, 40.96976089477539, 37.24747085571289, 40.53902816772461, 38.20211410522461, 36.258567810058594, 36.515830993652344, 42.12259292602539, 46.69261932373047, 38.383033752441406, 36.446556091308594, 38.80249786376953, 44.85722732543945, 36.583038330078125, 34.05555725097656, 36.63633346557617, 35.885887145996094, 41.70128631591797, 42.745941162109375, 33.845481872558594, 41.07625198364258, 34.128997802734375, 38.96480941772461, 37.185508728027344, 41.148887634277344, 52.81929397583008, 41.11485290527344, 36.29035949707031, 41.92060470581055, 35.677024841308594, 43.362327575683594, 40.64009094238281, 38.0919075012207, 37.371883392333984, 39.66139221191406, 37.80790710449219, 41.33683395385742, 39.174354553222656, 41.500335693359375, 37.84803009033203, 46.422706604003906, 37.82276916503906, 36.640464782714844, 35.89913558959961, 38.01829528808594, 34.30970001220703, 36.0218391418457, 34.953609466552734, 33.10615158081055, 33.48261260986328, 33.40835189819336, 36.548240661621094, 39.334495544433594, 35.2711181640625, 39.398624420166016, 39.5165901184082, 37.73605728149414, 36.73908615112305, 38.02548599243164, 47.964351654052734, 38.657649993896484, 37.433040618896484, 38.04591751098633, 37.885704040527344, 33.58662796020508, 39.16119384765625, 33.64609146118164, 37.927398681640625, 42.499717712402344, 41.64833450317383, 35.076881408691406, 36.78479766845703, 36.512760162353516, 33.392208099365234, 39.26426696777344, 37.11663818359375, 38.04765701293945, 34.43674087524414, 46.62608337402344, 36.558746337890625, 34.56916427612305, 34.900264739990234, 40.165687561035156, 39.09831237792969, 32.343502044677734, 35.735313415527344, 37.23988723754883, 34.3979606628418, 39.85441207885742, 33.573184967041016, 38.37276840209961, 37.95768356323242, 32.99015426635742, 34.55137252807617, 32.24910354614258, 39.870052337646484, 35.54540252685547, 35.080997467041016, 42.93663787841797, 35.44557189941406, 34.40361404418945, 32.7298698425293, 38.494407653808594, 39.46443176269531, 34.735137939453125, 33.35643005371094, 46.322364807128906, 35.231327056884766, 39.299739837646484, 50.62650680541992, 39.7165412902832, 39.3458137512207, 36.30119323730469, 34.82780075073242, 36.29673385620117, 33.26228713989258, 33.89995193481445, 33.59545135498047, 34.61491012573242, 34.281673431396484, 41.179649353027344, 41.065101623535156, 34.62958526611328, 34.46332931518555, 38.301239013671875, 42.936275482177734, 39.0369873046875, 37.516719818115234, 36.468780517578125, 42.19097137451172, 44.55954360961914, 46.48775100708008, 34.119998931884766, 37.585601806640625, 38.02836990356445, 39.151275634765625, 36.76671600341797, 39.954254150390625, 38.20878982543945, 32.915428161621094, 33.85551834106445, 35.96572494506836, 37.33180618286133, 36.236289978027344, 33.0962028503418]
stop_epoch = 293
patience = 50

print(f'출력된 val_loss의 값은 모두 {len(hist)} 개 입니다')
print("가장 낮은 val_loss는 ",min(hist))
print(f"{stop_epoch}번째 val_loss는 ",hist[-1])
print(f"가장 낮은 val_loss는 {hist.index(min(hist))+1} 번째 epoch 입니다")
if min(hist) < hist[-1]:
    print("Early Stop 구간의 val_loss가 가장 낮은 값은 아닙니다")
if hist.index(min(hist))+1 == stop_epoch - patience:
    print("Early Stop 에서 patience 앞의 val_loss가 가장 낮은 값 입니다")    
else:
    print("Early Stop 구간의 val_loss가 가장 낮은 값 입니다")    
'''